{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load_YoloV8_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "model = YOLO(r'runs\\detect\\train\\weights\\best.pt')  # load a custom model\n",
    "# model.predict(r\"..\\TruckDataset\\train\\images\\time3_frame5_003.jpg\", save=True, imgsz=640, conf=0.5, show=True)\n",
    "model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection__Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model(r\"..\\TruckDataset\\valid\\images\\time1_frame_142.jpg\")\n",
    "print('\\n output image shape: ', results[0].plot().shape)\n",
    "\n",
    "print('\\n NUM of Trucks in Frame: ', results[0].boxes.shape[0])\n",
    "im_array = results[0].plot()  # plot a BGR numpy array of predictions\n",
    "\n",
    "cv2.putText(im_array,f'Yolov8 Model - truck: {results[0].boxes.shape[0]}',(50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "\n",
    "im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "im.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection_Video_MultiTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of different times\n",
    "# a time have a start and end time \n",
    "# each of start and end time is a list: [h, m, s]\n",
    "## you can comment some of times in dictinary if have short time\n",
    "times = {'time1' : [[4, 56, 6], [4, 56, 30]],\n",
    "         'time2' : [[5, 51, 33], [5, 53, 3]],\n",
    "         'time3' : [[12, 4, 19], [12, 7, 0]],\n",
    "         'time4' : [[15, 10, 10], [15, 10, 40]],\n",
    "         'time5' : [[15, 21, 40], [15, 22, 26]],\n",
    "         'time6' : [[16, 27, 23], [16, 28, 20]],\n",
    "         'time7' : [[17, 24, 13], [17, 25, 0]],\n",
    "         'time8' : [[18, 1, 30], [18, 2, 30]],\n",
    "         'time9' : [[19, 14, 20], [19, 15, 13]]\n",
    "         }\n",
    "# times = {'time1' : [[4, 56, 6], [4, 58, 14]],\n",
    "#          'time2' : [[5, 51, 33], [5, 53, 3]],\n",
    "#          'time3' : [[6, 46, 22], [6, 43, 18]],\n",
    "#          'time4' : [[7, 42, 41], [7, 43, 33]],\n",
    "#          'time5' : [[12, 4, 19], [12, 15, 0]],\n",
    "#          'time6' : [[15, 10, 10], [15, 10, 40]],\n",
    "#          'time7' : [[15, 21, 40], [15, 22, 26]],\n",
    "#          'time8' : [[16, 27, 23], [16, 28, 20]],\n",
    "#          'time9' : [[17, 24, 13], [17, 25, 0]],\n",
    "#          'time10' : [[18, 1, 30], [18, 2, 30]],\n",
    "#          'time11' : [[19, 14, 20], [19, 16, 13]],\n",
    "#          'time12' : [[20, 45, 20], [20, 47, 38]],\n",
    "#          'time13' : [[20, 56, 0], [20, 57, 0]],\n",
    "#          'time14' : [[21, 52, 45], [21, 53, 45]],\n",
    "#          'time15' : [[23, 24, 30], [23, 25, 10]],\n",
    "#          'time16' : [[20, 25, 40], [20, 21, 30]]\n",
    "#          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r\"..\\..\\Data\\TruckVideo.mp4\")\n",
    "\n",
    "#output video setting\n",
    "output_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "output_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "output_fps = cap.get(cv2.CAP_PROP_FPS) \n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Use 'mp4v' codec for MP4 format\n",
    "\n",
    "output_path = 'Yolov8_annotated.mp4'\n",
    "\n",
    "out = cv2.VideoWriter(output_path, fourcc, output_fps, (output_width, output_height))\n",
    "\n",
    "time_step = 1\n",
    "\n",
    "#truck detection in different times\n",
    "## use esc+q to switch between times\n",
    "for t in times.keys():\n",
    "    start_time = times[t][0][0] * 3600 + times[t][0][1] * 60  + times[t][0][2]# Convert start time to seconds\n",
    "    end_time = times[t][1][0] * 3600 + times[t][1][1] * 60  + times[t][1][2] # Convert end time to seconds\n",
    "\n",
    "    # set start time for captured video\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "\n",
    "    frame_time = start_time\n",
    "    \n",
    "    # truck detection for time t\n",
    "    while frame_time <= end_time:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # use model for detection\n",
    "        with torch.no_grad():\n",
    "            results = model(frame)\n",
    "\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # write number of trucks on frame\n",
    "        cv2.putText(annotated_frame,f'Yolov8 Model - truck: {results[0].boxes.shape[0]}',(50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "            \n",
    "        # add frame to video\n",
    "        out.write(annotated_frame)\n",
    "        \n",
    "        # display annotated frame \n",
    "        cv2.imshow('YOLOV8', annotated_frame)\n",
    "\n",
    "        frame_time += time_step\n",
    "\n",
    "        # update capture start_time\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, frame_time * 1000)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break       \n",
    "        \n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection_Video_SingleTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(r\"..\\..\\Data\\TruckVideo.mp4\")\n",
    "\n",
    "# define start time of video for detection (secounds)\n",
    "## press esc+q to stop detection\n",
    "start_time = 4 * 3600 + 56 * 60  + 2\n",
    "\n",
    "# set start time for captured video\n",
    "cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)\n",
    "\n",
    "frame_time = start_time\n",
    "frame_count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # use model for detection\n",
    "    with torch.no_grad():\n",
    "        results = model(frame)\n",
    "\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    cv2.putText(annotated_frame,f'Yolov* Model - truck: {results[0].boxes.shape[0]}',(50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "    \n",
    "    # display annotated frame\n",
    "    cv2.imshow('YOLOV8', annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yolov8Venv",
   "language": "python",
   "name": "yolov8venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
